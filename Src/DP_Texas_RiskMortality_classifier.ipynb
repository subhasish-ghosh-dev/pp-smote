{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwy4e8RozvKy+pzTcfudE3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Voa776Kdqdg","executionInfo":{"status":"ok","timestamp":1704412802536,"user_tz":-360,"elapsed":31965,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"fcab0978-2af6-4ef9-97f3-ed77cdab8f03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.17.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.4)\n","Collecting scikit-learn<1.2.0,>=0.22.2 (from adversarial-robustness-toolbox)\n","  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 0.17.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed adversarial-robustness-toolbox-1.17.0 scikit-learn-1.1.3\n","Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu121)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: opacus\n","Successfully installed opacus-1.4.0\n"]}],"source":["!pip install xlrd\n","!pip install adversarial-robustness-toolbox\n","!pip install opacus"]},{"cell_type":"code","source":["import sys\n","import os\n","import pandas as pd\n","import numpy as np # for array operations\n","import requests, io # for HTTP requests and I/O commands\n","import matplotlib.pyplot as plt # for data visualization\n","from google.colab import drive\n","from numpy import mean\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n","from art.estimators.classification.pytorch import PyTorchClassifier\n","from opacus import PrivacyEngine\n","from tqdm import tqdm\n","import itertools\n","from sklearn.model_selection import StratifiedKFold\n","\n","drive.mount('/content/drive', force_remount=True)\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/'\n","dataset = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/PUDF_base1q2009_tab.csv\")\n","dataset = dataset.dropna()\n","dataset = dataset.drop(['RECORD_ID','PAT_AGE','PAT_STATUS'],axis=1)\n","dataset['SEX_CODE'] = pd.Categorical(dataset['SEX_CODE']).codes\n","dataset['ADMITTING_DIAGNOSIS'] = pd.Categorical(dataset['ADMITTING_DIAGNOSIS']).codes\n","dataset['PRINC_DIAG_CODE'] = pd.Categorical(dataset['PRINC_DIAG_CODE']).codes\n","dataset['OTH_DIAG_CODE_1'] = pd.Categorical(dataset['OTH_DIAG_CODE_1']).codes\n","dataset['OCCUR_DAY_1'] = pd.Categorical(dataset['OCCUR_DAY_1']).codes\n","dataset['OCCUR_CODE_1'] = pd.Categorical(dataset['OCCUR_CODE_1']).codes\n","dataset['HCFA_MDC'] = pd.Categorical(dataset['HCFA_MDC']).codes\n","dataset['ETHNICITY'] = pd.Categorical(dataset['ETHNICITY']).codes\n","dataset['SOURCE_OF_ADMISSION'] = pd.Categorical(dataset['SOURCE_OF_ADMISSION']).codes\n","dataset['RACE'] = pd.Categorical(dataset['RACE']).codes\n","dataset['LENGTH_OF_STAY'] = pd.Categorical(dataset['LENGTH_OF_STAY']).codes\n","dataset['TYPE_OF_ADMISSION'] = pd.Categorical(dataset['TYPE_OF_ADMISSION']).codes\n","dataset['APR_MDC'] = pd.Categorical(dataset['APR_MDC']).codes\n","dataset['HCFA_DRG'] = pd.Categorical(dataset['HCFA_DRG']).codes\n","dataset['APR_DRG'] = pd.Categorical(dataset['APR_DRG']).codes\n","dataset['ILLNESS_SEVERITY'] = pd.Categorical(dataset['ILLNESS_SEVERITY']).codes\n","dataset['RISK_MORTALITY'] = pd.Categorical(dataset['RISK_MORTALITY']).codes\n","RISK_MORTALITY_MAP = {1:0,2:1,3:2,4:3}\n","dataset['RISK_MORTALITY'] = dataset['RISK_MORTALITY'].replace(RISK_MORTALITY_MAP)\n","\n","#dataset = dataset.iloc[:380000]\n","#print(dataset.size)\n","dataset.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"AzI9pOevl2Vs","executionInfo":{"status":"ok","timestamp":1704413132265,"user_tz":-360,"elapsed":54863,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"134bc757-cab1-41cb-ee08-b4291a148fa7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-554a132b848c>:31: DtypeWarning: Columns (1,6,7,12) have mixed types. Specify dtype option on import or set low_memory=False.\n","  dataset = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/PUDF_base1q2009_tab.csv\")\n"]},{"output_type":"execute_result","data":{"text/plain":["        SEX_CODE  TYPE_OF_ADMISSION  SOURCE_OF_ADMISSION  LENGTH_OF_STAY  \\\n","737667         0                  1                    5              47   \n","737668         0                  1                    5              13   \n","737669         1                  2                    5              19   \n","737672         1                  2                    5              23   \n","737673         0                  2                    0               4   \n","\n","        RACE  ETHNICITY  ADMITTING_DIAGNOSIS  PRINC_DIAG_CODE  \\\n","737667    10          3                 1727             1989   \n","737668    10          3                 2857             3175   \n","737669     9          4                 1729             1991   \n","737672     9          4                 1668             1897   \n","737673     9          4                 1519              673   \n","\n","        OTH_DIAG_CODE_1  OCCUR_CODE_1  OCCUR_DAY_1  HCFA_MDC  APR_MDC  \\\n","737667             2480            37            0         4        4   \n","737668             2474            37            0         8        8   \n","737669             1998             2          689         4        4   \n","737672             4457             2          689         4        4   \n","737673             3627             2          689        10        8   \n","\n","        HCFA_DRG  APR_DRG  ILLNESS_SEVERITY  RISK_MORTALITY  \n","737667       725      302                 4               2  \n","737668       725      302                 4               3  \n","737669       725      304                 3               2  \n","737672       726      302                 3               0  \n","737673       732      142                 2               0  "],"text/html":["\n","  <div id=\"df-c5217cbd-ea29-4f6a-992e-922013af357f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SEX_CODE</th>\n","      <th>TYPE_OF_ADMISSION</th>\n","      <th>SOURCE_OF_ADMISSION</th>\n","      <th>LENGTH_OF_STAY</th>\n","      <th>RACE</th>\n","      <th>ETHNICITY</th>\n","      <th>ADMITTING_DIAGNOSIS</th>\n","      <th>PRINC_DIAG_CODE</th>\n","      <th>OTH_DIAG_CODE_1</th>\n","      <th>OCCUR_CODE_1</th>\n","      <th>OCCUR_DAY_1</th>\n","      <th>HCFA_MDC</th>\n","      <th>APR_MDC</th>\n","      <th>HCFA_DRG</th>\n","      <th>APR_DRG</th>\n","      <th>ILLNESS_SEVERITY</th>\n","      <th>RISK_MORTALITY</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>737667</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>47</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>1727</td>\n","      <td>1989</td>\n","      <td>2480</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>725</td>\n","      <td>302</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>737668</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>2857</td>\n","      <td>3175</td>\n","      <td>2474</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>725</td>\n","      <td>302</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>737669</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>19</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>1729</td>\n","      <td>1991</td>\n","      <td>1998</td>\n","      <td>2</td>\n","      <td>689</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>725</td>\n","      <td>304</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>737672</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>23</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>1668</td>\n","      <td>1897</td>\n","      <td>4457</td>\n","      <td>2</td>\n","      <td>689</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>726</td>\n","      <td>302</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>737673</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>1519</td>\n","      <td>673</td>\n","      <td>3627</td>\n","      <td>2</td>\n","      <td>689</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>732</td>\n","      <td>142</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5217cbd-ea29-4f6a-992e-922013af357f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c5217cbd-ea29-4f6a-992e-922013af357f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c5217cbd-ea29-4f6a-992e-922013af357f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4b89e691-c8a1-4afb-8d64-b2d084dd094a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b89e691-c8a1-4afb-8d64-b2d084dd094a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4b89e691-c8a1-4afb-8d64-b2d084dd094a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["data = {\n","  \"RISK_MORTALITY\": [0,1,2,3],\n","  \"Clients\": [len(dataset.query(\"RISK_MORTALITY == 0\")),\n","              len(dataset.query(\"RISK_MORTALITY == 1\")),\n","              len(dataset.query(\"RISK_MORTALITY == 2\")),\n","              len(dataset.query(\"RISK_MORTALITY == 3\"))]\n","}\n","\n","#load data into a DataFrame object:\n","df = pd.DataFrame(data)\n","\n","df.plot(kind = 'bar', x='RISK_MORTALITY',y = 'Clients')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"ApfThMv2mEZH","executionInfo":{"status":"ok","timestamp":1704381877272,"user_tz":-360,"elapsed":676,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"093cd205-0ed2-4a3b-fe11-92c0c15ce52a"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","sm_dataset_0 = dataset.query(\"RISK_MORTALITY == 0\").iloc[1:40000]\n","sm_dataset_1 = dataset.query(\"RISK_MORTALITY == 1\").iloc[1:40000]\n","sm_dataset_2 = dataset.query(\"RISK_MORTALITY == 2\").iloc[1:40000]\n","sm_dataset_3 = dataset.query(\"RISK_MORTALITY == 3\").iloc[1:40000]\n","sm_dataset = pd.concat([sm_dataset_0, sm_dataset_1, sm_dataset_2, sm_dataset_3])\n","sm_dataset.head()\n","print(len(sm_dataset_0))\n","print(len(sm_dataset_1))\n","print(len(sm_dataset_2))\n","print(len(sm_dataset_3))\n","#scaler = MinMaxScaler()\n","#X_orig = sm_dataset.to_numpy()\n","#X_orig = scaler.fit_transform(X_orig)\n","#np.unique(X_orig[:-1])\n","#X_orig.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ums-w5YimJHZ","executionInfo":{"status":"ok","timestamp":1704381955486,"user_tz":-360,"elapsed":444,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"1d9c2a1d-11d9-42f4-d3ca-7043cf9b6870"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["39999\n","39999\n","39999\n","23610\n"]}]},{"cell_type":"code","source":["#X_train_1 = sm_dataset_0.to_numpy()[1:60000,:]\n","#X_train_2 = sm_dataset_1.to_numpy()[60000:119998,:]\n","#X_train_3 = sm_dataset_2.to_numpy()[60000:119998,:]\n","#X_train_4 = sm_dataset_3.to_numpy()[1:60000,:]\n","#X_train_5 =np.concatenate((X_train_1,X_train_2,X_train_3,X_train_4),axis=0)\n","X_train_5 = sm_dataset.to_numpy()\n","X_train_5.shape\n","np.unique(X_train_5[:,-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iK2Ja30CmPcn","executionInfo":{"status":"ok","timestamp":1704381960388,"user_tz":-360,"elapsed":427,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"668bda0f-8456-4f6e-d938-ed54f40e4c8b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3], dtype=int16)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["X_train_5[:,:16].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7HHZfVPmT8p","executionInfo":{"status":"ok","timestamp":1704357851976,"user_tz":-360,"elapsed":16,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"fda73aa0-41a9-48eb-f975-08d18982aee6"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(143607, 16)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["smt = SMOTE()\n","X = X_train_5[:,:16]\n","y = X_train_5[:,-1]\n","\n","X_train_5, y_train_5 = smt.fit_resample(X, y)\n","np.unique(y_train_5)\n","X_train_5[:,:16].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdv0yyQAmqVO","executionInfo":{"status":"ok","timestamp":1704381977870,"user_tz":-360,"elapsed":12785,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"e888df67-3f46-40fd-8c29-744bdd3e8037"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(159996, 16)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class Data(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.from_numpy(X.astype(np.float32))\n","        self.y = torch.from_numpy(y.astype(np.float32))\n","        self.len = self.X.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len\n","class HospitalPatientClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden1 = nn.Linear(16, 128)\n","        self.act1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.hidden2 = nn.Linear(128, 64)\n","        self.act2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.3)\n","        self.hidden3 = nn.Linear(64, 32)\n","        self.act3 = nn.ReLU()\n","        self.hidden4 = nn.Linear(32, 16)\n","        self.act4 = nn.ReLU()\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.output = nn.Linear(16, 4)\n","\n","    def forward(self, x):\n","        x = self.act1(self.hidden1(x))\n","        x = self.dropout1(x)\n","        x = self.act2(self.hidden2(x))\n","        x = self.dropout2(x)\n","        x = self.act3(self.hidden3(x))\n","        x = self.dropout3(x)\n","        x = self.act4(self.hidden4(x))\n","        x = self.output(x)\n","        return x\n","\n","def accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","def evaluate(model, test_dataloader):\n","    model.eval()\n","    loss_arr = []\n","    accuracy_arr = []\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      _, predicted = torch.max(y_pred.data, 1)\n","      acc = (predicted.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracy_arr.append(acc)\n","    return np.mean(accuracy_arr)\n","def model_train(model, train_dataloader, test_dataloader, n_epochs=5):\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","    model.train()\n","    for epoch in range(n_epochs):\n","      for (data, target) in train_dataloader:\n","            y_pred = model(data)\n","            loss = loss_fn(y_pred, target.long())\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","    accuracies=[]\n","    model.eval()\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      _, predicted = torch.max(y_pred.data, 1)\n","      acc = (predicted.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracies.append(acc)\n","    return np.mean(accuracies),np.std(accuracies)\n","def test(model, test_dataloader, privacy_engine, delta):\n","    acc = evaluate(model, test_dataloader)\n","    #print(acc)\n","    #printstr = \"\\n----------------------------\\n\" f\"Test Accuracy: {acc}\"\n","    if privacy_engine:\n","        epsilon = privacy_engine.get_epsilon(delta)\n","        #printstr += f\" (ε = {epsilon:.2f}, δ = {delta})\"\n","    #print(printstr + \"\\n----------------------------\\n\")\n","    return acc, epsilon, delta\n","#for epoch in range(1, 2):\n","    #test(model, test_dataloader, privacy_engine, device)"],"metadata":{"id":"ZvkDsiDmm6aZ","executionInfo":{"status":"ok","timestamp":1704382072976,"user_tz":-360,"elapsed":456,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def _splitData(X_train_5,y_train_5):\n","  X_train, X_test, y_train, y_test = train_test_split(X_train_5,y_train_5, random_state=104,test_size=0.5,shuffle=True)\n","  scaler = MinMaxScaler()\n","  label_encoder = LabelEncoder()\n","  X_train = scaler.fit_transform(X_train)\n","  X_test = scaler.fit_transform(X_test)\n","  label_encoder.fit(y_train)\n","  label_encoder.fit(y_test)\n","  y_train = label_encoder.transform(y_train)\n","  y_test = label_encoder.transform(y_test)\n","  train_data = Data(X_train, np.array(y_train))\n","  train_dataloader = DataLoader(dataset=train_data, batch_size=128, shuffle=True)\n","\n","  test_data = Data(X_test, np.array(y_test))\n","  test_dataloader = DataLoader(dataset=test_data, batch_size=128, shuffle=True)\n","\n","  return train_dataloader, test_dataloader, X_train, X_test, y_train, y_test\n","def train_dp(model, train_dataloader, optimizer, EPOCH):\n","  loss_fn = nn.CrossEntropyLoss()\n","  model.train()\n","  loss_values = []\n","  total = 0\n","  correct = 0\n","  for epoch in range(EPOCH):\n","    for (data, target) in train_dataloader:\n","      y_pred = model(data)\n","      loss = loss_fn(y_pred, target.long())\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","  return model\n","def _buildModel(train_dataloader, test_dataloader):\n","  device= \"cpu\"\n","  model = HospitalPatientClassifier()\n","  model_acc_mean, model_acc_std = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","  loss_values=[]\n","  accs=[]\n","  delta = 1 / len(train_dataloader.dataset)\n","  EPOCH=5\n","  model = HospitalPatientClassifier()\n","  loss_fn = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","  privacy_engine = PrivacyEngine()\n","  model, optimizer, train_dataloader = privacy_engine.make_private(\n","    module=model,\n","    optimizer=optimizer,\n","    data_loader=train_dataloader,\n","    noise_multiplier=50.0,\n","    max_grad_norm=1.0,\n","  )\n","\n","  dp_model = train_dp(model, train_dataloader, optimizer, EPOCH)\n","  acc, epsilon, delta = test(dp_model, test_dataloader, privacy_engine, delta)\n","  return dp_model, model_acc_mean, model_acc_std, acc, epsilon, delta\n","\n","def calc_precision_recall(predicted, actual, positive_value=1):\n","    score = 0  # both predicted and actual are positive\n","    num_positive_predicted = 0  # predicted positive\n","    num_positive_actual = 0  # actual positive\n","    for i in range(len(predicted)):\n","        if predicted[i] == positive_value:\n","            num_positive_predicted += 1\n","        if actual[i] == positive_value:\n","            num_positive_actual += 1\n","        if predicted[i] == actual[i]:\n","            if predicted[i] == positive_value:\n","                score += 1\n","\n","    if num_positive_predicted == 0:\n","        precision = 1\n","    else:\n","        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n","    if num_positive_actual == 0:\n","        recall = 1\n","    else:\n","        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n","\n","    return precision, recall\n","\n","def _attackMIA(X_train, X_test, y_train, y_test, model):\n","  loss_fn = nn.CrossEntropyLoss()\n","  attack_train_ratio = 0.5\n","  attack_train_size = int(len(X_train) * attack_train_ratio)\n","  attack_test_size = int(len(X_test) * attack_train_ratio)\n","\n","  mlp_art_model = PyTorchClassifier(model=model, loss=loss_fn, input_shape=(16,), nb_classes=4)\n","  mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n","  mlp_attack_bb.fit(X_train[:attack_train_size].astype(np.float32),y_train[:attack_train_size].astype(np.float32),\n","                    X_test[:attack_test_size].astype(np.float32), y_test[:attack_test_size].astype(np.float32))\n","  mlp_inferred_train_bb = mlp_attack_bb.infer(X_train[attack_train_size:].astype(np.float32), y_train[attack_train_size:])\n","  mlp_inferred_test_bb = mlp_attack_bb.infer(X_test[attack_test_size:].astype(np.float32), y_test[attack_test_size:])\n","\n","  mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n","  mlp_test_acc_bb = 1-(np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n","  mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n","\n","  #print(f\"Members Accuracy: {mlp_train_acc_bb:.4f}\")\n","  #print(f\"Non Members Accuracy {mlp_test_acc_bb:.4f}\")\n","  #print(f\"Attack Accuracy {mlp_acc_bb:.4f}\")\n","\n","  precision, recall = calc_precision_recall(np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb)),\n","                              np.concatenate((np.ones(len(mlp_inferred_train_bb)), np.zeros(len(mlp_inferred_test_bb)))))\n","  y_train_pred = np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb))\n","  y_train_true = np.concatenate((np.ones_like(mlp_inferred_train_bb), np.zeros_like(mlp_inferred_test_bb)))\n","  #print(classification_report(y_pred=y_train_pred, y_true=y_train_true))\n","  return mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall\n","\n","#for epoch in range(1, 2):\n","#  train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(X_train_5, y_train_5)\n","#  model = TrafficClassifier()\n","#  model_acc_mean, model_acc_std = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","#  print(model_acc_mean)"],"metadata":{"id":"iByUfNfUmuQo","executionInfo":{"status":"ok","timestamp":1704392159337,"user_tz":-360,"elapsed":405,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import concurrent.futures\n","import threading\n","\n","num_iterations = 20\n","model_acc_means = []\n","model_acc_stds = []\n","accs = []\n","epsilons = []\n","deltas = []\n","member  = []\n","nonmember = []\n","att = []\n","prec = []\n","rec = []\n","\n","def execAttack(lock):\n","  with lock:\n","    #print(\"Attack executed.\")\n","    train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(X_train_5, y_train_5)\n","    dp_model, model_acc_mean, model_acc_std, acc, epsilon, delta = _buildModel(train_dataloader, test_dataloader)\n","    mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall = _attackMIA(X_train, X_test, y_train, y_test, dp_model)\n","    print(f\"{acc:4f},{mlp_train_acc_bb:4f},{mlp_test_acc_bb:4f},{mlp_acc_bb:4f},{precision:4f},{recall:4f}\")\n","    model_acc_means.append(model_acc_mean)\n","    model_acc_stds.append(model_acc_std)\n","    accs.append(acc)\n","    epsilons.append(epsilon)\n","    deltas.append(delta)\n","    member.append(mlp_train_acc_bb)\n","    nonmember.append(mlp_test_acc_bb)\n","    att.append(mlp_acc_bb)\n","    prec.append(precision)\n","    rec.append(recall)\n","\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    lock = threading.Lock()\n","    futures = [executor.submit(execAttack,lock) for _ in range(num_iterations)]\n","    concurrent.futures.wait(futures)\n","ppldf = pd.DataFrame()\n","ppldf['model_acc'] = np.array(model_acc_means)\n","ppldf['model_acc-std'] = np.array(model_acc_stds)\n","ppldf['dp_model_acc'] = np.array(accs)\n","ppldf['epsilon'] = np.array(epsilons)\n","ppldf['delta'] = np.array(deltas)\n","ppldf['Member_Accuracy'] = np.array(member)\n","ppldf['Non_Member_Accuracy'] = np.array(nonmember)\n","ppldf['Attack_accuracy'] = np.array(att)\n","ppldf['Precision'] = np.array(prec)\n","ppldf['Recall'] = np.array(rec)\n","#ppldf.head()\n","ppldf.to_csv(\"/content/drive/MyDrive/Colab Notebooks/results/dp/Classes_4/result_dp2_50_0.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMtMWHwfnb-I","outputId":"09759ded-5ad9-4a24-ba41-132112b572c4","executionInfo":{"status":"ok","timestamp":1704394497750,"user_tz":-360,"elapsed":2332304,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.226081,0.513963,0.518463,0.516213,0.516286,0.513963\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.249656,0.739543,0.267757,0.503650,0.502480,0.739543\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.254843,0.518163,0.541739,0.529951,0.530674,0.518163\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.250908,0.523588,0.501288,0.512438,0.512166,0.523588\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.297206,0.478312,0.539188,0.508750,0.509317,0.478312\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.248894,0.506913,0.503213,0.505063,0.505044,0.506913\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.283831,0.512938,0.528788,0.520863,0.521199,0.512938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.313408,0.515313,0.518238,0.516775,0.516825,0.515313\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.259956,0.515638,0.532738,0.524188,0.524609,0.515638\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.293868,0.516438,0.536863,0.526651,0.527206,0.516438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.293158,0.523938,0.543339,0.533638,0.534304,0.523938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.333332,0.524238,0.533063,0.528651,0.528906,0.524238\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.303071,0.521513,0.526263,0.523888,0.524002,0.521513\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.283458,0.570939,0.465937,0.518438,0.516686,0.570939\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.277243,0.472737,0.548514,0.510625,0.511496,0.472737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.288569,0.522463,0.546439,0.534451,0.535297,0.522463\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.248707,0.750669,0.253781,0.502225,0.501486,0.750669\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.266794,0.522338,0.541014,0.531676,0.532279,0.522338\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.300083,0.517938,0.522663,0.520301,0.520397,0.517938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.272234,0.517238,0.541414,0.529326,0.530052,0.517238\n"]}]}]}