{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2BLlwrltwLBe7OJ2PQry/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rf19R_btSUu","executionInfo":{"status":"ok","timestamp":1704473869430,"user_tz":-360,"elapsed":52598,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"95d9a130-ca4e-4168-d8fb-75badad9f2d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.17.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.4)\n","Collecting scikit-learn<1.2.0,>=0.22.2 (from adversarial-robustness-toolbox)\n","  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 0.17.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed adversarial-robustness-toolbox-1.17.0 scikit-learn-1.1.3\n","Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu121)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: opacus\n","Successfully installed opacus-1.4.0\n"]}],"source":["!pip install xlrd\n","!pip install adversarial-robustness-toolbox\n","!pip install opacus"]},{"cell_type":"code","source":["import sys\n","import os\n","import pandas as pd\n","import numpy as np # for array operations\n","import requests, io # for HTTP requests and I/O commands\n","import matplotlib.pyplot as plt # for data visualization\n","from google.colab import drive\n","from numpy import mean\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n","from art.estimators.classification.pytorch import PyTorchClassifier\n","from opacus import PrivacyEngine\n","from tqdm import tqdm\n","import itertools\n","from sklearn.model_selection import StratifiedKFold\n","\n","drive.mount('/content/drive', force_remount=True)\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/'\n","dataset = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/UNSW_NB15_MIA.csv\")\n","dataset = dataset.dropna()\n","\n","dataset = dataset.drop(['sport', 'dsport', 'stcpb', 'dtcpb', 'Stime', 'Ltime', 'sbytes', 'dbytes', 'Sload', 'Dload'], axis=1)\n","dataset['proto'] = pd.Categorical(dataset['proto']).codes\n","dataset['state'] = pd.Categorical(dataset['state']).codes\n","dataset['service'] = pd.Categorical(dataset['service']).codes\n","dataset['attack_cat'] = pd.Categorical(dataset['attack_cat']).codes\n","ATTACK_CAT_MAP = {1:0,2:1,3:2,4:3, 5:4,6:5,7:6,8:7}\n","dataset['attack_cat'] = dataset['attack_cat'].replace(ATTACK_CAT_MAP)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09-_7BKYtU0F","executionInfo":{"status":"ok","timestamp":1704473931982,"user_tz":-360,"elapsed":54104,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"3bcfc469-9c43-4111-faab-b5dea79b090e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["sm_dataset_0 = dataset.query(\"attack_cat == 0\").iloc[1:28000]\n","sm_dataset_1 = dataset.query(\"attack_cat == 1\").iloc[1:28000]\n","sm_dataset_2 = dataset.query(\"attack_cat == 2\").iloc[1:28000]\n","sm_dataset_3 = dataset.query(\"attack_cat == 3\").iloc[1:28000]\n","sm_dataset_4 = dataset.query(\"attack_cat == 4\").iloc[1:28000]\n","sm_dataset_5 = dataset.query(\"attack_cat == 5\").iloc[1:28000]\n","sm_dataset_6 = dataset.query(\"attack_cat == 6\").iloc[1:28000]\n","sm_dataset_7 = dataset.query(\"attack_cat == 7\").iloc[1:28000]\n","sm_dataset = pd.concat([sm_dataset_0, sm_dataset_1, sm_dataset_2, sm_dataset_3, sm_dataset_4,sm_dataset_5,sm_dataset_6,sm_dataset_7])\n","print(len(sm_dataset_0))\n","print(len(sm_dataset_1))\n","print(len(sm_dataset_2))\n","print(len(sm_dataset_3))\n","print(len(sm_dataset_4))\n","print(len(sm_dataset_5))\n","print(len(sm_dataset_6))\n","print(len(sm_dataset_7))\n","sm_dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"XlOYJvxlthD-","executionInfo":{"status":"ok","timestamp":1704473936055,"user_tz":-360,"elapsed":755,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"7e186fba-93d6-48b6-fa40-f264834a4996"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["571\n","7\n","283\n","4098\n","7174\n","225\n","16\n","20095\n"]},{"output_type":"execute_result","data":{"text/plain":["     proto  state       dur  sttl  dttl  sloss  dloss  service  Spkts  Dpkts  \\\n","167      0      1  0.388297   254   252      2      1        4     10      8   \n","168      0      1  0.180398   254   252      2      1        4     10      6   \n","169      0      1  0.175691   254   252      2      1        4     10      6   \n","171      0      1  0.432149   254   252      2      1        4     10      8   \n","173      0      1  0.163739   254   252      2      1        4     10      6   \n","\n","     ...  is_ftp_login  ct_ftp_cmd  ct_srv_src  ct_srv_dst  ct_dst_ltm  \\\n","167  ...             0           0          12          11           3   \n","168  ...             0           0          12          11           3   \n","169  ...             0           0          12          11           2   \n","171  ...             0           0          12          11           2   \n","173  ...             0           0          12          11           3   \n","\n","     ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n","167            3                 3                 1               3   \n","168            3                 3                 1               3   \n","169            3                 3                 1               2   \n","171            3                 3                 1               2   \n","173            3                 3                 1               3   \n","\n","     attack_cat  \n","167           0  \n","168           0  \n","169           0  \n","171           0  \n","173           0  \n","\n","[5 rows x 34 columns]"],"text/html":["\n","  <div id=\"df-def98058-1cfb-48a1-87e0-f74f44c15e6f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>proto</th>\n","      <th>state</th>\n","      <th>dur</th>\n","      <th>sttl</th>\n","      <th>dttl</th>\n","      <th>sloss</th>\n","      <th>dloss</th>\n","      <th>service</th>\n","      <th>Spkts</th>\n","      <th>Dpkts</th>\n","      <th>...</th>\n","      <th>is_ftp_login</th>\n","      <th>ct_ftp_cmd</th>\n","      <th>ct_srv_src</th>\n","      <th>ct_srv_dst</th>\n","      <th>ct_dst_ltm</th>\n","      <th>ct_src_ ltm</th>\n","      <th>ct_src_dport_ltm</th>\n","      <th>ct_dst_sport_ltm</th>\n","      <th>ct_dst_src_ltm</th>\n","      <th>attack_cat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>167</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.388297</td>\n","      <td>254</td>\n","      <td>252</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>168</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.180398</td>\n","      <td>254</td>\n","      <td>252</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>169</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.175691</td>\n","      <td>254</td>\n","      <td>252</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>171</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.432149</td>\n","      <td>254</td>\n","      <td>252</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>173</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.163739</td>\n","      <td>254</td>\n","      <td>252</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-def98058-1cfb-48a1-87e0-f74f44c15e6f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-def98058-1cfb-48a1-87e0-f74f44c15e6f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-def98058-1cfb-48a1-87e0-f74f44c15e6f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e214afa1-1e7c-4261-a629-a0e55392c0f4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e214afa1-1e7c-4261-a629-a0e55392c0f4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e214afa1-1e7c-4261-a629-a0e55392c0f4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["data = {\n","  \"attack_cat\": [0,1,2,3,4,5,6,7],\n","  \"Clients\": [len(sm_dataset.query(\"attack_cat == 0\")),\n","              len(sm_dataset.query(\"attack_cat == 1\")),\n","              len(sm_dataset.query(\"attack_cat == 2\")),\n","              len(sm_dataset.query(\"attack_cat == 3\")),\n","              len(sm_dataset.query(\"attack_cat == 4\")),\n","              len(sm_dataset.query(\"attack_cat == 5\")),\n","              len(sm_dataset.query(\"attack_cat == 6\")),\n","              len(sm_dataset.query(\"attack_cat == 7\"))\n","              ]\n","}\n","\n","#load data into a DataFrame object:\n","df = pd.DataFrame(data)\n","\n","df.plot(kind = 'bar', x='attack_cat',y = 'Clients')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"doIlwQzPtiFO","executionInfo":{"status":"ok","timestamp":1704473942957,"user_tz":-360,"elapsed":469,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"82cb0af2-ceed-477a-ca05-a32c513df3d3"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["X_train_5 = sm_dataset.to_numpy()\n","X_train_5.shape\n","#X_orig"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fe_Tw7Bdtlwy","executionInfo":{"status":"ok","timestamp":1704473951853,"user_tz":-360,"elapsed":396,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"eaa0181c-6b8a-4373-ee83-da3e812ec161"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32469, 34)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["smt = SMOTE()\n","\n","X = X_train_5[:,:33]\n","y = X_train_5[:,-1]\n","\n","X_train_5, y_train_5 = smt.fit_resample(X, y)\n","np.unique(y_train_5)\n","X_train_5[:,:33].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ih_DNowntpW1","executionInfo":{"status":"ok","timestamp":1704473956867,"user_tz":-360,"elapsed":770,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"976ea5ac-2838-4c8c-b298-4bfa7fd52505"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(160760, 33)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Convert data to torch tensors\n","class Data(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.from_numpy(X.astype(np.float32))\n","        self.y = torch.from_numpy(y.astype(np.float32))\n","        self.len = self.X.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len\n","\n","\n"],"metadata":{"id":"sou11wGtukEt","executionInfo":{"status":"ok","timestamp":1704473960374,"user_tz":-360,"elapsed":15,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class TrafficClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden1 = nn.Linear(33, 128)\n","        self.act1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.hidden2 = nn.Linear(128, 64)\n","        self.act2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.3)\n","        self.hidden3 = nn.Linear(64, 32)\n","        self.act3 = nn.ReLU()\n","        self.hidden4 = nn.Linear(32, 16)\n","        self.act4 = nn.ReLU()\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.output = nn.Linear(16, 8)\n","\n","    def forward(self, x):\n","        x = self.act1(self.hidden1(x))\n","        x = self.dropout1(x)\n","        x = self.act2(self.hidden2(x))\n","        x = self.dropout2(x)\n","        x = self.act3(self.hidden3(x))\n","        x = self.dropout3(x)\n","        x = self.act4(self.hidden4(x))\n","        x = self.output(x)\n","        return x\n","\n"],"metadata":{"id":"iOF26SyvuxnW","executionInfo":{"status":"ok","timestamp":1704473968042,"user_tz":-360,"elapsed":404,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","def evaluate(model, test_dataloader):\n","    model.eval()\n","    loss_arr = []\n","    accuracy_arr = []\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      _, predicted = torch.max(y_pred.data, 1)\n","      acc = (predicted.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracy_arr.append(acc)\n","    return np.mean(accuracy_arr)"],"metadata":{"id":"Zp8d3Ajwv6_T","executionInfo":{"status":"ok","timestamp":1704473973018,"user_tz":-360,"elapsed":620,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def model_train(model, train_dataloader, test_dataloader, n_epochs=5):\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","    model.train()\n","    for epoch in range(n_epochs):\n","      for (data, target) in train_dataloader:\n","            y_pred = model(data)\n","            loss = loss_fn(y_pred, target.long())\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","    accuracies=[]\n","    model.eval()\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      _, predicted = torch.max(y_pred.data, 1)\n","      acc = (predicted.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracies.append(acc)\n","    return np.mean(accuracies),np.std(accuracies)\n","#X_train, X_test, y_train, y_test = train_test_split(X_train_5,y_train_5, random_state=104,test_size=0.5,shuffle=True)\n","#scaler = MinMaxScaler()\n","#label_encoder = LabelEncoder()\n","#X_train = scaler.fit_transform(X_train)\n","#X_test = scaler.fit_transform(X_test)\n","#label_encoder.fit(y_train)\n","#label_encoder.fit(y_test)\n","#y_train = label_encoder.transform(y_train)\n","#y_test = label_encoder.transform(y_test)\n","#train_data = Data(X_train, np.array(y_train))\n","#train_dataloader = DataLoader(dataset=train_data, batch_size=128, shuffle=True)\n","\n","#test_data = Data(X_test, np.array(y_test))\n","#test_dataloader = DataLoader(dataset=test_data, batch_size=128, shuffle=True)\n","#for i in range(1,2):\n","#    model = TrafficClassifier()\n","#    model_acc_mean = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","#    print(\"Baseline: %.2f%% \" % (model_acc_mean))\n","\n","# evaluate the model\n","#mean = np.mean(accuracies)\n","#std = np.std(accuracies)\n","#print(\"Baseline: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))"],"metadata":{"id":"4oM9aQQ8v9dC","executionInfo":{"status":"ok","timestamp":1704473976816,"user_tz":-360,"elapsed":20,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def test(model, test_dataloader, privacy_engine, delta):\n","    acc = evaluate(model, test_dataloader)\n","    #print(acc)\n","    #printstr = \"\\n----------------------------\\n\" f\"Test Accuracy: {acc}\"\n","    if privacy_engine:\n","        epsilon = privacy_engine.get_epsilon(delta)\n","        #printstr += f\" (ε = {epsilon:.2f}, δ = {delta})\"\n","    #print(printstr + \"\\n----------------------------\\n\")\n","    return acc, epsilon, delta\n","#for epoch in range(1, 2):\n","    #test(model, test_dataloader, privacy_engine, device)"],"metadata":{"id":"tSs5qWAtzI4f","executionInfo":{"status":"ok","timestamp":1704473981748,"user_tz":-360,"elapsed":587,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def _splitData(X_train_5, y_train_5):\n","  X_train, X_test, y_train, y_test = train_test_split(X_train_5,y_train_5, random_state=104,test_size=0.5,shuffle=True)\n","  scaler = MinMaxScaler()\n","  label_encoder = LabelEncoder()\n","  X_train = scaler.fit_transform(X_train)\n","  X_test = scaler.fit_transform(X_test)\n","  label_encoder.fit(y_train)\n","  label_encoder.fit(y_test)\n","  y_train = label_encoder.transform(y_train)\n","  y_test = label_encoder.transform(y_test)\n","  train_data = Data(X_train, np.array(y_train))\n","  train_dataloader = DataLoader(dataset=train_data, batch_size=128, shuffle=True)\n","\n","  test_data = Data(X_test, np.array(y_test))\n","  test_dataloader = DataLoader(dataset=test_data, batch_size=128, shuffle=True)\n","\n","  return train_dataloader, test_dataloader, X_train, X_test, y_train, y_test\n","def _buildModel(train_dataloader, test_dataloader):\n","  device= \"cpu\"\n","  model = TrafficClassifier()\n","  model_acc_mean, model_acc_std = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","  loss_values=[]\n","  accs=[]\n","  delta = 1 / len(train_dataloader.dataset)\n","  EPOCH=5\n","  model = TrafficClassifier()\n","  loss_fn = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","  privacy_engine = PrivacyEngine()\n","  model, optimizer, train_dataloader = privacy_engine.make_private(\n","    module=model,\n","    optimizer=optimizer,\n","    data_loader=train_dataloader,\n","    noise_multiplier=0.35,\n","    max_grad_norm=1.0,\n","  )\n","\n","  model.train()\n","  loss_values = []\n","  total = 0\n","  correct = 0\n","  for epoch in range(EPOCH):\n","    for (data, target) in train_dataloader:\n","      y_pred = model(data)\n","      loss = loss_fn(y_pred, target.long())\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","  #dp_model = train(model, train_dataloader, optimizer, EPOCH, delta, privacy_engine)\n","  acc, epsilon, delta = test(model, test_dataloader, privacy_engine, delta)\n","  return model, model_acc_mean, model_acc_std, acc, epsilon, delta\n","\n","def calc_precision_recall(predicted, actual, positive_value=1):\n","    score = 0  # both predicted and actual are positive\n","    num_positive_predicted = 0  # predicted positive\n","    num_positive_actual = 0  # actual positive\n","    for i in range(len(predicted)):\n","        if predicted[i] == positive_value:\n","            num_positive_predicted += 1\n","        if actual[i] == positive_value:\n","            num_positive_actual += 1\n","        if predicted[i] == actual[i]:\n","            if predicted[i] == positive_value:\n","                score += 1\n","\n","    if num_positive_predicted == 0:\n","        precision = 1\n","    else:\n","        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n","    if num_positive_actual == 0:\n","        recall = 1\n","    else:\n","        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n","\n","    return precision, recall\n","\n","def _attackMIA(X_train, X_test, y_train, y_test, model):\n","  loss_fn = nn.CrossEntropyLoss()\n","  attack_train_ratio = 0.5\n","  attack_train_size = int(len(X_train) * attack_train_ratio)\n","  attack_test_size = int(len(X_test) * attack_train_ratio)\n","\n","  mlp_art_model = PyTorchClassifier(model=model, loss=loss_fn, input_shape=(33,), nb_classes=8)\n","  mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n","  mlp_attack_bb.fit(X_train[:attack_train_size].astype(np.float32),y_train[:attack_train_size].astype(np.float32),\n","                    X_test[:attack_test_size].astype(np.float32), y_test[:attack_test_size].astype(np.float32))\n","  mlp_inferred_train_bb = mlp_attack_bb.infer(X_train[attack_train_size:].astype(np.float32), y_train[attack_train_size:])\n","  mlp_inferred_test_bb = mlp_attack_bb.infer(X_test[attack_test_size:].astype(np.float32), y_test[attack_test_size:])\n","\n","  mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n","  mlp_test_acc_bb = 1-(np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n","  mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n","\n","  #print(f\"Members Accuracy: {mlp_train_acc_bb:.4f}\")\n","  #print(f\"Non Members Accuracy {mlp_test_acc_bb:.4f}\")\n","  #print(f\"Attack Accuracy {mlp_acc_bb:.4f}\")\n","\n","  precision, recall = calc_precision_recall(np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb)),\n","                              np.concatenate((np.ones(len(mlp_inferred_train_bb)), np.zeros(len(mlp_inferred_test_bb)))))\n","  y_train_pred = np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb))\n","  y_train_true = np.concatenate((np.ones_like(mlp_inferred_train_bb), np.zeros_like(mlp_inferred_test_bb)))\n","  #print(classification_report(y_pred=y_train_pred, y_true=y_train_true))\n","  return mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall\n","\n","#for epoch in range(1, 2):\n","#  train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(X_train_5, y_train_5)\n","#  model = TrafficClassifier()\n","#  model_acc_mean, model_acc_std = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","#  print(model_acc_mean)"],"metadata":{"id":"W0OFOdDBzJuS","executionInfo":{"status":"ok","timestamp":1704477744197,"user_tz":-360,"elapsed":840,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import concurrent.futures\n","import threading\n","\n","num_iterations = 20\n","model_acc_means = []\n","model_acc_stds = []\n","accs = []\n","epsilons = []\n","deltas = []\n","member  = []\n","nonmember = []\n","att = []\n","prec = []\n","rec = []\n","\n","def execAttack(lock):\n","  with lock:\n","    #print(\"Attack executed.\")\n","    train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(X_train_5, y_train_5)\n","    dp_model, model_acc_mean, model_acc_std, acc, epsilon, delta = _buildModel(train_dataloader, test_dataloader)\n","    mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall = _attackMIA(X_train, X_test, y_train, y_test, dp_model)\n","    print(f\"{acc:4f},{mlp_train_acc_bb:4f},{mlp_test_acc_bb:4f},{mlp_acc_bb:4f},{precision:4f},{recall:4f}\")\n","    model_acc_means.append(model_acc_mean)\n","    model_acc_stds.append(model_acc_std)\n","    accs.append(acc)\n","    epsilons.append(epsilon)\n","    deltas.append(delta)\n","    member.append(mlp_train_acc_bb)\n","    nonmember.append(mlp_test_acc_bb)\n","    att.append(mlp_acc_bb)\n","    prec.append(precision)\n","    rec.append(recall)\n","\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    lock = threading.Lock()\n","    futures = [executor.submit(execAttack,lock) for _ in range(num_iterations)]\n","    concurrent.futures.wait(futures)\n","ppldf = pd.DataFrame()\n","ppldf['model_acc'] = np.array(model_acc_means)\n","ppldf['model_acc-std'] = np.array(model_acc_stds)\n","ppldf['dp_model_acc'] = np.array(accs)\n","ppldf['epsilon'] = np.array(epsilons)\n","ppldf['delta'] = np.array(deltas)\n","ppldf['Member_Accuracy'] = np.array(member)\n","ppldf['Non_Member_Accuracy'] = np.array(nonmember)\n","ppldf['Attack_accuracy'] = np.array(att)\n","ppldf['Precision'] = np.array(prec)\n","ppldf['Recall'] = np.array(rec)\n","#ppldf.head()\n","ppldf.to_csv(\"/content/drive/MyDrive/Colab Notebooks/results/dp/Classes_8/result_dp2_pt35.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZtPm5SW0a9E","executionInfo":{"status":"ok","timestamp":1704480902369,"user_tz":-360,"elapsed":3152770,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"1a8eb5d2-784b-4c0a-d153-f4d05a96236e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.832408,0.740483,0.727171,0.733827,0.730755,0.740483\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.814293,0.727743,0.705051,0.716397,0.711596,0.727743\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.835584,0.750112,0.751779,0.750946,0.751365,0.750112\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.822767,0.720129,0.723613,0.721871,0.722647,0.720129\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.830654,0.755387,0.753297,0.754342,0.753811,0.755387\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.835979,0.740931,0.735382,0.738156,0.736842,0.740931\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.806682,0.736352,0.736104,0.736228,0.736169,0.736352\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.821497,0.750858,0.744091,0.747474,0.745811,0.750858\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.810114,0.747698,0.752650,0.750174,0.751419,0.747698\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.814520,0.715377,0.693232,0.704305,0.699878,0.715377\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.834909,0.736128,0.740931,0.738529,0.739680,0.736128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.808101,0.725902,0.728987,0.727445,0.728149,0.725902\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.836612,0.741130,0.742822,0.741976,0.742386,0.741130\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.832061,0.754939,0.755934,0.755437,0.755691,0.754939\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.837735,0.745285,0.756706,0.750995,0.753895,0.745285\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.822156,0.752550,0.750062,0.751306,0.750683,0.752550\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.827866,0.730406,0.735581,0.732993,0.734205,0.730406\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.827011,0.762553,0.759343,0.760948,0.760113,0.762553\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.839862,0.740582,0.742423,0.741503,0.741948,0.740582\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.825428,0.760090,0.758771,0.759430,0.759089,0.760090\n"]}]}]}