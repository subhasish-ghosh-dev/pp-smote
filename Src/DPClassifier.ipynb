{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPj2Ql1UiRW2cYHon+5tXWw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhgyppD4dIUt","executionInfo":{"status":"ok","timestamp":1704266104530,"user_tz":-360,"elapsed":47968,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"8b5b3e7f-18bb-4e8d-fdcd-b5e32be49be3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.17.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.4)\n","Collecting scikit-learn<1.2.0,>=0.22.2 (from adversarial-robustness-toolbox)\n","  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 0.17.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed adversarial-robustness-toolbox-1.17.0 scikit-learn-1.1.3\n","Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu121)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: opacus\n","Successfully installed opacus-1.4.0\n"]}],"source":["!pip install xlrd\n","!pip install adversarial-robustness-toolbox\n","!pip install opacus"]},{"cell_type":"code","source":["import sys\n","import os\n","import pandas as pd\n","import numpy as np # for array operations\n","import requests, io # for HTTP requests and I/O commands\n","import matplotlib.pyplot as plt # for data visualization\n","from google.colab import drive\n","from numpy import mean\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n","from art.estimators.classification.pytorch import PyTorchClassifier\n","from opacus import PrivacyEngine\n","from tqdm import tqdm\n","import itertools\n","from sklearn.model_selection import StratifiedKFold\n","\n","drive.mount('/content/drive', force_remount=True)\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/'\n","#dataset = pd.read_excel(r\"/content/drive/MyDrive/Colab Notebooks/default_of_credit_card_clients.xlsx\")\n","dataset = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/creditcard.csv\")\n","#print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PB2HoSqCdU0D","executionInfo":{"status":"ok","timestamp":1704266247659,"user_tz":-360,"elapsed":49859,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"54743eec-476c-43a1-a2d3-efe7fe131759"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#print(len(dataset.query(\"default_payment_next_month ==0\")))\n","#print(len(dataset.query(\"default_payment_next_month ==1\")))\n","\n","data = {\n","  \"Class\": [0,1],\n","  \"Clients\": [len(dataset.query(\"Class == 0\")),\n","              len(dataset.query(\"Class == 1\"))]\n","}\n","\n","#load data into a DataFrame object:\n","df = pd.DataFrame(data)\n","\n","df.plot(kind = 'bar', x='Class',y = 'Clients')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"4ytBstkDdxvr","executionInfo":{"status":"ok","timestamp":1704266285571,"user_tz":-360,"elapsed":852,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"659d0b11-3de4-4075-9c52-5bb8fabdcd24"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["X = dataset.drop(['Class'],axis=1)[1:50000]\n","y = dataset.Class[1:50000]\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBOWCjW-d1di","executionInfo":{"status":"ok","timestamp":1704266293360,"user_tz":-360,"elapsed":429,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"cadc4726-21b5-4329-f3fa-0e23cc37aad9"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49999,)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["smt = SMOTE()\n","X_sm, y_sm = smt.fit_resample(X,y)\n","df_sm = pd.concat([X_sm, y_sm], axis=1, join='inner')\n","data = {\n","  \"Class\": [0,1],\n","  \"Clients\": [len(df_sm.query(\"Class ==0\")),\n","              len(df_sm.query(\"Class ==1\"))]\n","}\n","\n","#load data into a DataFrame object:\n","df_p = pd.DataFrame(data)\n","\n","df_p.plot(kind = 'bar', x='Class',y = 'Clients')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"IW-T4Nv2d476","executionInfo":{"status":"ok","timestamp":1704266298265,"user_tz":-360,"elapsed":2128,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}},"outputId":"35e81e8f-48d9-49eb-9dad-8f6246813856"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Convert data to torch tensors\n","class Data(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.from_numpy(X.astype(np.float32))\n","        self.y = torch.from_numpy(y.astype(np.float32)).reshape(-1, 1)\n","        self.len = self.X.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len\n","\n","\n"],"metadata":{"id":"LyioYAFCeSUq","executionInfo":{"status":"ok","timestamp":1704266304215,"user_tz":-360,"elapsed":415,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class FraudClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden1 = nn.Linear(29, 128)\n","        self.act1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.hidden2 = nn.Linear(128, 64)\n","        self.act2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.3)\n","        self.hidden3 = nn.Linear(64, 16)\n","        self.act3 = nn.ReLU()\n","        self.hidden4 = nn.Linear(16, 8)\n","        self.act4 = nn.ReLU()\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.output = nn.Linear(8, 1)\n","        self.act_output = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.act1(self.hidden1(x))\n","        x = self.dropout1(x)\n","        x = self.act2(self.hidden2(x))\n","        x = self.dropout2(x)\n","        x = self.act3(self.hidden3(x))\n","        x = self.dropout3(x)\n","        x = self.act4(self.hidden4(x))\n","        x = self.act_output(self.output(x))\n","        return x\n","\n"],"metadata":{"id":"c9weCfMyeg4X","executionInfo":{"status":"ok","timestamp":1704266307230,"user_tz":-360,"elapsed":18,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","def evaluate(model, test_dataloader):\n","    model.eval()\n","    loss_arr = []\n","    accuracy_arr = []\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      acc = (y_pred.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracy_arr.append(acc)\n","    return np.mean(accuracy_arr)"],"metadata":{"id":"WYZub0oSevts","executionInfo":{"status":"ok","timestamp":1704266309686,"user_tz":-360,"elapsed":10,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def model_train(model, train_dataloader, test_dataloader, n_epochs=5):\n","    loss_fn = nn.BCELoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n","    model.train()\n","    for epoch in range(n_epochs):\n","      for (data, target) in train_dataloader:\n","            y_pred = model(data)\n","            loss = loss_fn(y_pred, target)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","    accuracies=[]\n","    model.eval()\n","    for (data, target) in test_dataloader:\n","      y_pred = model(data)\n","      acc = (y_pred.round() == target).float().mean()\n","      acc = float(acc)\n","      accuracies.append(acc)\n","    mean = np.mean(accuracies)\n","    std = np.std(accuracies)\n","    #print(\"Baseline: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))\n","    return mean,std\n","\n","#for i in range(1,2):\n","#    accuracies = model_train(model)\n","\n","# evaluate the model\n","#mean = np.mean(accuracies)\n","#std = np.std(accuracies)\n","#print(\"Baseline: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))"],"metadata":{"id":"3lTYzDTQ7V65","executionInfo":{"status":"ok","timestamp":1704266313902,"user_tz":-360,"elapsed":13,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train(model, train_dataloader, optimizer, epochs, delta, privacy_engine):\n","    loss_fn = torch.nn.BCELoss()\n","    model.train()\n","    loss_values = []\n","    total = 0\n","    correct = 0\n","    print(correct)\n","    for epoch in range(epochs):\n","      for (data, target) in train_dataloader:\n","        y_pred = model(data)\n","        loss = loss_fn(y_pred, target)\n","        print(loss)\n","        loss_values.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    #epsilon = privacy_engine.get_epsilon(delta)\n","    #print(\n","    #    f\"Train Epoch: {epoch} \\t\"\n","    #    f\"Loss: {np.mean(loss_values):.6f} \"\n","    #    f\"(ε = {epsilon:.2f}, δ = {delta})\")\n","    return model\n","#for epoch in range(1, 10):\n","#  train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(df_sm)\n","#  train(model, train_dataloader, optimizer, epoch, device=\"cpu\", delta=1e-5)\n"],"metadata":{"id":"nG2GoZDje5Tz","executionInfo":{"status":"ok","timestamp":1704266318339,"user_tz":-360,"elapsed":20,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def test(model, test_dataloader, privacy_engine, delta):\n","    acc = evaluate(model, test_dataloader)\n","    #print(acc)\n","    #printstr = \"\\n----------------------------\\n\" f\"Test Accuracy: {acc}\"\n","    if privacy_engine:\n","        epsilon = privacy_engine.get_epsilon(delta)\n","        #printstr += f\" (ε = {epsilon:.2f}, δ = {delta})\"\n","    #print(printstr + \"\\n----------------------------\\n\")\n","    return acc, epsilon, delta\n","#for epoch in range(1, 2):\n","    #test(model, test_dataloader, privacy_engine, device)"],"metadata":{"id":"Wyq3qCHnnK_-","executionInfo":{"status":"ok","timestamp":1704266322473,"user_tz":-360,"elapsed":20,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#mlp_art_model = PyTorchClassifier(model=model, loss=loss_fn, optimizer=optimizer, input_shape=(29,), nb_classes=2)\n","\n","#train_pred = mlp_art_model.predict(X_train.astype(np.float32))\n","#acc = (train_pred.round() == y_train).mean()\n","#acc = float(acc)\n","#print('Base model Train accuracy: ', acc)\n","\n","#test_pred = mlp_art_model.predict(X_test.astype(np.float32))\n","#acc = (train_pred.round() == y_test).mean()\n","#acc = float(acc)\n","#print('Base model Test accuracy: ', acc)"],"metadata":{"id":"K1VAIM4qfp4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n","\n","#mlp_attack_bb.fit(X_train.astype(np.float32),y_train.astype(np.float32),X_test.astype(np.float32), y_test.astype(np.float32))\n","\n","#mlp_inferred_train_bb = mlp_attack_bb.infer(X_train.astype(np.float32), y_train)\n","#mlp_inferred_test_bb = mlp_attack_bb.infer(X_test.astype(np.float32), y_test)\n","\n","#mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n","#mlp_test_acc_bb = 1-(np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n","#mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n","\n","#print(f\"Members Accuracy: {mlp_train_acc_bb:.4f}\")\n","#print(f\"Non Members Accuracy {mlp_test_acc_bb:.4f}\")\n","#print(f\"Attack Accuracy {mlp_acc_bb:.4f}\")\n"],"metadata":{"id":"vPpZK0-Af257"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from sklearn.metrics import classification_report\n","\n","#y_train_pred = np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb))\n","#y_train_true = np.concatenate((np.ones_like(mlp_inferred_train_bb), np.zeros_like(mlp_inferred_test_bb)))\n","#print(classification_report(y_pred=y_train_pred, y_true=y_train_true))"],"metadata":{"id":"voEksZlIJ5t5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"UwqIa-lCC1ho","executionInfo":{"status":"ok","timestamp":1704266336745,"user_tz":-360,"elapsed":597,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"}}},"outputs":[],"source":["def _splitData(df_sm):\n","  batch_size = 128\n","  X_o = df_sm.drop(['Time','Class'],axis=1)\n","  y_o = df_sm.Class\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X_o,y_o, random_state=104,test_size=0.5,shuffle=True)\n","\n","  #X_test = df_sm_sm_sm.drop(['Time', 'Class'],axis=1)\n","  #y_test = df_sm_sm_sm.Class\n","\n","  scaler = MinMaxScaler()\n","  label_encoder = LabelEncoder()\n","\n","  X_train = scaler.fit_transform(X_train)\n","  X_test = scaler.fit_transform(X_test)\n","  label_encoder.fit(y_train)\n","  label_encoder.fit(y_test)\n","  y_train = label_encoder.transform(y_train)\n","  y_test = label_encoder.transform(y_test)\n","  # Instantiate training and test data\n","  train_data = Data(X_train, np.array(y_train))\n","  train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","\n","  test_data = Data(X_test, np.array(y_test))\n","  test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n","\n","  # Check it's working\n","  #for batch, (X, y) in enumerate(train_dataloader):\n","  #    print(f\"Batch: {batch+1}\")\n","  #    print(f\"X shape: {X.shape}\")\n","  #    print(f\"y shape: {y.shape}\")\n","  #    break\n","  return train_dataloader, test_dataloader, X_train, X_test, y_train, y_test\n","\n","def _buildModel(train_dataloader, test_dataloader):\n","  device= \"cpu\"\n","  model = FraudClassifier()\n","  model_acc_mean, model_acc_std = model_train(model,train_dataloader, test_dataloader, n_epochs=5)\n","  loss_values=[]\n","  accs=[]\n","  delta = 1 / len(train_dataloader.dataset)\n","  EPOCH=5\n","  model = FraudClassifier()\n","  loss_fn = nn.BCELoss()\n","  optimizer = optim.SGD(model.parameters(), lr=0.01)\n","  privacy_engine = PrivacyEngine()\n","  model, optimizer, train_dataloader = privacy_engine.make_private(\n","    module=model,\n","    optimizer=optimizer,\n","    data_loader=train_dataloader,\n","    noise_multiplier=0.26,\n","    max_grad_norm=1.0,\n","  )\n","\n","  model.train()\n","  loss_values = []\n","  total = 0\n","  correct = 0\n","  for epoch in range(EPOCH):\n","    for (data, target) in train_dataloader:\n","      y_pred = model(data)\n","      loss = loss_fn(y_pred, target)\n","      #print(loss)\n","      loss_values.append(loss.item())\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","  #dp_model = train(model, train_dataloader, optimizer, EPOCH, delta, privacy_engine)\n","  acc, epsilon, delta = test(model, test_dataloader, privacy_engine, delta)\n","  return model, model_acc_mean, model_acc_std, acc, epsilon, delta\n","\n","def calc_precision_recall(predicted, actual, positive_value=1):\n","    score = 0  # both predicted and actual are positive\n","    num_positive_predicted = 0  # predicted positive\n","    num_positive_actual = 0  # actual positive\n","    for i in range(len(predicted)):\n","        if predicted[i] == positive_value:\n","            num_positive_predicted += 1\n","        if actual[i] == positive_value:\n","            num_positive_actual += 1\n","        if predicted[i] == actual[i]:\n","            if predicted[i] == positive_value:\n","                score += 1\n","\n","    if num_positive_predicted == 0:\n","        precision = 1\n","    else:\n","        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n","    if num_positive_actual == 0:\n","        recall = 1\n","    else:\n","        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n","\n","    return precision, recall\n","\n","def _attackMIA(X_train, X_test, y_train, y_test, model):\n","  loss_fn = torch.nn.BCELoss()\n","  attack_train_ratio = 0.5\n","  attack_train_size = int(len(X_train) * attack_train_ratio)\n","  attack_test_size = int(len(X_test) * attack_train_ratio)\n","\n","  mlp_art_model = PyTorchClassifier(model=model, loss=loss_fn, input_shape=(29,), nb_classes=2)\n","  mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n","  mlp_attack_bb.fit(X_train[:attack_train_size].astype(np.float32),y_train[:attack_train_size].astype(np.float32),\n","                    X_test[:attack_test_size].astype(np.float32), y_test[:attack_test_size].astype(np.float32))\n","  mlp_inferred_train_bb = mlp_attack_bb.infer(X_train[attack_train_size:].astype(np.float32), y_train[attack_train_size:])\n","  mlp_inferred_test_bb = mlp_attack_bb.infer(X_test[attack_test_size:].astype(np.float32), y_test[attack_test_size:])\n","\n","  mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n","  mlp_test_acc_bb = 1-(np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n","  mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n","\n","  #print(f\"Members Accuracy: {mlp_train_acc_bb:.4f}\")\n","  #print(f\"Non Members Accuracy {mlp_test_acc_bb:.4f}\")\n","  #print(f\"Attack Accuracy {mlp_acc_bb:.4f}\")\n","\n","  precision, recall = calc_precision_recall(np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb)),\n","                              np.concatenate((np.ones(len(mlp_inferred_train_bb)), np.zeros(len(mlp_inferred_test_bb)))))\n","  y_train_pred = np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb))\n","  y_train_true = np.concatenate((np.ones_like(mlp_inferred_train_bb), np.zeros_like(mlp_inferred_test_bb)))\n","  #print(classification_report(y_pred=y_train_pred, y_true=y_train_true))\n","  return mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall\n","\n","#for epoch in range(1, 10):\n","#  train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(df_sm)\n","#  _buildModel(train_dataloader, test_dataloader)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":969650,"status":"ok","timestamp":1704267318584,"user":{"displayName":"Subhasish Ghosh","userId":"09231805416479081409"},"user_tz":-360},"id":"zQrX6mbQDq05","outputId":"8f16ef8e-cf41-4c04-9d77-535ca3796d42"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.834021,0.606555,0.607318,0.606937,0.607018,0.606555\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.892147,0.527441,0.536307,0.531874,0.532159,0.527441\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.922162,0.619795,0.615943,0.617869,0.617417,0.619795\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.738547,0.741354,0.722539,0.731947,0.727663,0.741354\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.928081,0.570368,0.566156,0.568262,0.567976,0.570368\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.901746,0.554762,0.555244,0.555003,0.555029,0.554762\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.930662,0.610407,0.604870,0.607639,0.607046,0.610407\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.775974,0.565835,0.568122,0.566978,0.567132,0.565835\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.839419,0.614900,0.609685,0.612292,0.611710,0.614900\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.937006,0.666653,0.658389,0.662521,0.661189,0.666653\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.833586,0.650245,0.650445,0.650345,0.650375,0.650245\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.782121,0.686031,0.684386,0.685208,0.684904,0.686031\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.727793,0.620918,0.620798,0.620858,0.620843,0.620918\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.725263,0.600497,0.580920,0.590708,0.588967,0.600497\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.940111,0.640777,0.625933,0.633355,0.631404,0.640777\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.837126,0.676803,0.624569,0.650686,0.643206,0.676803\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.517883,0.441587,0.806066,0.623827,0.694842,0.441587\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.732541,0.589585,0.590548,0.590067,0.590153,0.589585\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.960096,0.686111,0.684265,0.685188,0.684847,0.686111\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","/usr/local/lib/python3.10/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n","  z = np.log((np.exp(t) + q - 1) / q)\n"]},{"output_type":"stream","name":"stdout","text":["0.801465,0.610848,0.613857,0.612353,0.612692,0.610848\n"]}],"source":["import concurrent.futures\n","import threading\n","\n","num_iterations = 20\n","model_acc_means = []\n","model_acc_stds = []\n","accs = []\n","epsilons = []\n","deltas = []\n","member  = []\n","nonmember = []\n","att = []\n","prec = []\n","rec = []\n","\n","def execAttack(lock):\n","  with lock:\n","    #print(\"Attack executed.\")\n","    train_dataloader, test_dataloader,X_train, X_test, y_train, y_test = _splitData(df_sm)\n","    dp_model, model_acc_mean, model_acc_std, acc, epsilon, delta = _buildModel(train_dataloader, test_dataloader)\n","    mlp_train_acc_bb, mlp_test_acc_bb, mlp_acc_bb, precision, recall = _attackMIA(X_train, X_test, y_train, y_test, dp_model)\n","    print(f\"{acc:4f},{mlp_train_acc_bb:4f},{mlp_test_acc_bb:4f},{mlp_acc_bb:4f},{precision:4f},{recall:4f}\")\n","    model_acc_means.append(model_acc_mean)\n","    model_acc_stds.append(model_acc_std)\n","    accs.append(acc)\n","    epsilons.append(epsilon)\n","    deltas.append(delta)\n","    member.append(mlp_train_acc_bb)\n","    nonmember.append(mlp_test_acc_bb)\n","    att.append(mlp_acc_bb)\n","    prec.append(precision)\n","    rec.append(recall)\n","\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    lock = threading.Lock()\n","    futures = [executor.submit(execAttack,lock) for _ in range(num_iterations)]\n","    concurrent.futures.wait(futures)\n","ppldf = pd.DataFrame()\n","ppldf['model_acc'] = np.array(model_acc_means)\n","ppldf['model_acc-std'] = np.array(model_acc_stds)\n","ppldf['dp_model_acc'] = np.array(accs)\n","ppldf['epsilon'] = np.array(epsilons)\n","ppldf['delta'] = np.array(deltas)\n","ppldf['Member_Accuracy'] = np.array(member)\n","ppldf['Non_Member_Accuracy'] = np.array(nonmember)\n","ppldf['Attack_accuracy'] = np.array(att)\n","ppldf['Precision'] = np.array(prec)\n","ppldf['Recall'] = np.array(rec)\n","#ppldf.head()\n","ppldf.to_csv(\"/content/drive/MyDrive/Colab Notebooks/results/dp/Classes_2/result_dp2_pt26.csv\")"]}]}